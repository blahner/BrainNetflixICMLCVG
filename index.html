<!DOCTYPE html>
<html lang="en">
<head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <title>A Systematic Comparison of fMRI-to-video Reconstruction Techniques</title>
      <!-- Updated: Added Google Fonts -->
      <link rel="preconnect" href="https://fonts.googleapis.com">
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link href="https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,400;0,700;1,400;1,700&family=Open+Sans:wght@400;700&display=swap" rel="stylesheet">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.0/css/all.min.css">
      <link rel="stylesheet" href="styles.css">
      <script type="text/javascript" src="https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js"></script>
      <script type="text/javascript" src="https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js"></script>
      <script type="text/javascript">
          Bokeh.set_log_level("info");
      </script>
</head>
<body>
    <div class="content-container">

    <!-- Title card -->
    <section id="title-card">
        <h1>A Systematic Comparison of fMRI-to-video Reconstruction Techniques</h1>
        <h2>Presented at ICML 2024's Controllable Video Generation (CVG) workshop</h2>
      <div class="authors">
        Camilo Fosco*, Benjamin Lahner*, Bowen Pan, Alex Andonian, Emilie Josephs, Alex Lascelles, Aude Oliva
      </div>
    <div class="buttons">
        <a href="images/icml2024_CVGworkshop.pdf" target="_blank">
            <i class="fas fa-star"></i> Paper
        </a>
        <!--
        <a href="https://github.com/cfosco/brain2video" target="_blank">
            <i class="fab fa-github"></i> Project Github
        </a>
        <a href="gifs.html">
          <i class="fas fa-images"></i> Compare Reconstructions
        </a>
      -->
    </div>
    </section>
    <div>
      <section>
    <h2>Summary</h2>
    <p>
    We reconstruct videos from functional magnetic resonance imaging (fMRI) data of humans viewing these videos. This work focuses on comparing the reconstruction quality
    of the videos using various methodologies. Specifically, we vary the backbone video generation models between Zeroscope V2 [1], Modelscope [2], Stable
    Video Diffusion [3], and Hotshot-XL [4] and assess video reconstruction quality on videos from the BOLD Moments Dataset [5] and 
    CC2017 [6] dataset. We find that Zeroscope V2 performs best on both BMD and CC2017, and the general pipeline achieves better quantitative and qualitative
    reconstructions than other leading methodologies. We describe the full reconstruction pipeline in detail in our
    <a href="https://blahner.github.io/BrainNetflixECCV/">ECCV 2024 paper</a>. Interactive reconstruction examples on this webpage coming soon.
    </p>
    </section>
    </div>
    <div>
    <section>
      <img src="images/workshop_teaser-cropped.jpg" alt="reconstruction comparison overview">
    </section>
    </div>

    <div>
      <section>
        <h2>Acknowledgements</h2>
        <p>
        This research was funded by the Multidisciplinary University Research Initiative (MURI) award by the Army Research Office (grant No. W911NF-23-1-0277) to A.O; the
        MIT EECS MathWorks Fellowship to B.L.; the MIT EECS
        MathWorks Fellowship to C.F.
        </p>
      </section>
    </div>

    <div>
    <section>
    <h2>References</h2>
    <ol>
      <li>Hysts. Zeroscope v2. https://huggingface.co/
        spaces/hysts/zeroscope-v2, 2024. Accessed:
        2024-06-05.
      </li>
      <li>
        Wang, J., Yuan, H., Chen, D., Zhang, Y., Wang, X., and
        Zhang, S. Modelscope text-to-video technical report.
        arXiv preprint arXiv:2308.06571, 2023.
      </li>
      <li>
        Blattmann, A., Dockhorn, T., Kulal, S., Mendelevitch, D.,
        Kilian, M., Lorenz, D., Levi, Y., English, Z., Voleti, V.,
        Letts, A., et al. Stable video diffusion: Scaling latent
        video diffusion models to large datasets. arXiv preprint
        arXiv:2311.15127, 2023a.
      </li>
      <li>
        Mullan, J., Crawbuck, D., and Sastry, A. Hotshot-
        XL, October 2023. URL https://github.com/
        hotshotco/hotshot-xl.
      </li>
      <li>
        Lahner, B., Dwivedi, K., Iamshchinina, P., Graumann, M., Lascelles, A., Roig, G., ... & Cichy, R. (2024). Modeling short visual events through the BOLD moments video fMRI dataset and metadata. Nature Communications, 15(1), 6241.
      </li>
      <li>
        Wen, H., Shi, J., Zhang, Y., Lu, K. H., Cao, J., & Liu, Z. (2018). Neural encoding and decoding with deep learning for dynamic natural vision. Cerebral cortex, 28(12), 4136-4160.
      </li>
    </ol>
  </section>
    </div>
  
</body>
</html>
